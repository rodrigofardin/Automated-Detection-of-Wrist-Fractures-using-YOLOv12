{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d4f68e",
   "metadata": {},
   "source": [
    "# split_check - Notebook de uso (replica do original)\n",
    "\n",
    "Este notebook reproduz os passos do notebook original: divisão por paciente, verificações de vazamento (patient/study/filestem/duplicatas/temporal), e preparação do dataset no formato YOLO.\n",
    "\n",
    "ATENÇÃO: este notebook pressupõe que o arquivo `dataset.csv` foi obtido do site oficial do dataset. Por favor baixe o dataset no site oficial antes de executar (não inclua dados sensíveis no repositório público)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc4d36",
   "metadata": {},
   "source": [
    "## 1) Preparação do ambiente e imports\n",
    "Descomente a linha de instalação se precisar instalar dependências a partir de `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7becc1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projeto em C:\\Users\\rodri\\Desktop\\GRAZPEDWRI-DX-Split\n",
      "split_check importado\n"
     ]
    }
   ],
   "source": [
    "# Instale dependências (descomente se necessário)\n",
    "# %pip install -r requirements.txt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "# Garantir que o projeto está no sys.path para imports locais\n",
    "proj_root = Path('.').resolve()\n",
    "if str(proj_root) not in sys.path:\n",
    "    sys.path.insert(0, str(proj_root))\n",
    "print('Projeto em', proj_root)\n",
    "\n",
    "# Importar o módulo novo (split_check)\n",
    "import split_check as sc\n",
    "# Configure logging uma vez para o notebook (prevenindo handlers duplicados)\n",
    "try:\n",
    "    sc.configure_logging()\n",
    "except Exception:\n",
    "    # configure_logging pode não existir em versões antigas do módulo; ignorar sem quebrar\n",
    "    pass\n",
    "print('split_check versão (módulo):', getattr(sc, '__version__', 'n/a')) if hasattr(sc, '__version__') else print('split_check importado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72a0a5",
   "metadata": {},
   "source": [
    "## 2) Caminhos e configuração\n",
    "Ajuste os caminhos abaixo conforme sua estrutura local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad9c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_PATH: 14825193\\dataset.csv\n",
      "OUTPUT_DIR: splits\n",
      "Images dir: images \n",
      "Labels dir: labels\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = Path('14825193/dataset.csv')\n",
    "OUTPUT_DIR = Path('splits')\n",
    "PATIENT_COL = 'patient_id'\n",
    "STUDY_COL = 'study_number'\n",
    "DO_ORGANIZE = True  # mudar para True quando quiser copiar imagens/labels\n",
    "IMG_DIR = Path('images')\n",
    "LBL_DIR = Path('labels')\n",
    "DST_ROOT = Path('dataset_yolo')\n",
    "SEED = 42\n",
    "\n",
    "print('CSV_PATH:', CSV_PATH)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n",
    "print('Images dir:', IMG_DIR, '\\nLabels dir:', LBL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91901b8",
   "metadata": {},
   "source": [
    "## 3) Carregar dataset\n",
    "Tenta carregar o CSV do dataset; se não encontrado, avisa e interrompe (não gera dados sintéticos automaticamente aqui, para evitar confusão em produção)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bdc899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Dataset carregado: 20327 amostras, 17 colunas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filestem</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_number</th>\n",
       "      <th>timehash</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>laterality</th>\n",
       "      <th>projection</th>\n",
       "      <th>initial_exam</th>\n",
       "      <th>ao_classification</th>\n",
       "      <th>cast</th>\n",
       "      <th>diagnosis_uncertain</th>\n",
       "      <th>osteopenia</th>\n",
       "      <th>fracture_visible</th>\n",
       "      <th>metal</th>\n",
       "      <th>pixel_spacing</th>\n",
       "      <th>device_manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_1297860395_01_WRI-L1_M014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1297860395</td>\n",
       "      <td>M</td>\n",
       "      <td>14.1</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23r-M/2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_1297860435_01_WRI-L2_M014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1297860435</td>\n",
       "      <td>M</td>\n",
       "      <td>14.1</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23r-M/2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_0354485735_01_WRI-R1_F012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>354485735</td>\n",
       "      <td>F</td>\n",
       "      <td>12.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23r-M/2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filestem  patient_id  study_number    timehash  \\\n",
       "0  0001_1297860395_01_WRI-L1_M014           1             1  1297860395   \n",
       "1  0001_1297860435_01_WRI-L2_M014           1             1  1297860435   \n",
       "2  0002_0354485735_01_WRI-R1_F012           2             1   354485735   \n",
       "\n",
       "  gender   age laterality  projection  initial_exam ao_classification  cast  \\\n",
       "0      M  14.1          L           1           1.0         23r-M/2.1   NaN   \n",
       "1      M  14.1          L           2           1.0         23r-M/2.1   NaN   \n",
       "2      F  12.0          R           1           1.0         23r-M/2.1   NaN   \n",
       "\n",
       "   diagnosis_uncertain  osteopenia  fracture_visible  metal  pixel_spacing  \\\n",
       "0                  NaN         NaN               NaN    NaN          0.144   \n",
       "1                  NaN         NaN               1.0    NaN          0.144   \n",
       "2                  1.0         NaN               NaN    NaN          0.144   \n",
       "\n",
       "  device_manufacturer  \n",
       "0             Siemens  \n",
       "1             Siemens  \n",
       "2             Siemens  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amostras: 20327 | pacientes únicos: 6091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = sc.load_dataset(CSV_PATH)\n",
    "except FileNotFoundError as e:\n",
    "    print('❌', e)\n",
    "    print('Por favor baixe o dataset no site oficial e coloque em', CSV_PATH)\n",
    "    raise\n",
    "\n",
    "# Exibir primeiras linhas e estatísticas básicas\n",
    "display(df.head(3))\n",
    "print(f'Total amostras: {len(df)} | pacientes únicos: {df[PATIENT_COL].nunique() if PATIENT_COL in df.columns else \"N/A\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f5fc1",
   "metadata": {},
   "source": [
    "## 4) Dividir por paciente (sem vazamento) e salvar splits\n",
    "Usamos a função `split_by_patient` do módulo para obter `train/val/test` e salvamos os CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d30ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Split feito: train=14170, val=4118, test=2039 samples\n",
      "INFO: Splits salvos em splits\n"
     ]
    }
   ],
   "source": [
    "# Realizar split\n",
    "train_df, val_df, test_df = sc.split_by_patient(df, patient_col=PATIENT_COL, seed=SEED)\n",
    "\n",
    "# Salvar splits\n",
    "sc.save_splits(train_df, val_df, test_df, out_dir=OUTPUT_DIR, patient_col=PATIENT_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe52369c",
   "metadata": {},
   "source": [
    "## 5) Verificações (patient, study, filestem, duplicatas, temporal)\n",
    "As verificações abaixo seguem a lógica do notebook original. Algumas checagens apenas imprimem avisos; outras lançam erro se vazamento for encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d7d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [patient_id] train∩val=0, train∩test=0, val∩test=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [study_number] train∩val=11, train∩test=9, val∩test=9\n",
      "INFO: [filestem] train∩val=0, train∩test=0, val∩test=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves a checar: ['patient_id', 'study_number', 'filestem']\n"
     ]
    }
   ],
   "source": [
    "# Checagens simples por chaves\n",
    "keys_to_check = [k for k in [PATIENT_COL, 'study_number', 'filestem', 'filepath'] if k in df.columns]\n",
    "print('Chaves a checar:', keys_to_check)\n",
    "sc.check_group_overlap(train_df, val_df, test_df, keys_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f221b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [patient_id] train∩val=0, train∩test=0, val∩test=0\n",
      "INFO: [study_number] train∩val=11, train∩test=9, val∩test=9\n",
      "INFO: [filestem] train∩val=0, train∩test=0, val∩test=0\n",
      "INFO: study_key train∩val: 0 interseções\n",
      "INFO: study_key train∩test: 0 interseções\n",
      "INFO: study_key val∩test: 0 interseções\n",
      "INFO: [duplicatas exatas] train∩val=0, train∩test=0, val∩test=0\n",
      "INFO: [temporal timehash] max(train)=2011-12-22 01:12:28 | min(val)=1972-06-22 10:11:39 | min(test)=1973-07-13 06:21:15\n",
      "WARNING: ⚠️ Possível overlap temporal (ok se split por paciente)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaves a checar: ['patient_id', 'study_number', 'filestem']\n",
      "✅ Nenhum vazamento por study_key detectado (se aplicável)\n"
     ]
    }
   ],
   "source": [
    "# Checagens simples por chaves\n",
    "keys_to_check = [k for k in [PATIENT_COL, 'study_number', 'filestem', 'filepath'] if k in df.columns]\n",
    "print('Chaves a checar:', keys_to_check)\n",
    "sc.check_group_overlap(train_df, val_df, test_df, keys_to_check)\n",
    "\n",
    "# Checagem por estudo (se existir) — garante study_key disjuntas\n",
    "if 'study_number' in df.columns:\n",
    "    make_study_key = lambda d: (d[PATIENT_COL].astype(str) + '#' + d['study_number'].astype(str))\n",
    "    try:\n",
    "        sc.check_disjoint(make_study_key(train_df), make_study_key(val_df), 'study_key train∩val')\n",
    "        sc.check_disjoint(make_study_key(train_df), make_study_key(test_df), 'study_key train∩test')\n",
    "        sc.check_disjoint(make_study_key(val_df), make_study_key(test_df), 'study_key val∩test')\n",
    "        print('✅ Nenhum vazamento por study_key detectado (se aplicável)')\n",
    "    except AssertionError as e:\n",
    "        print('❌ Vazamento detectado em study_key:', e)\n",
    "\n",
    "# Duplicatas exatas (ignorar colunas não relevantes)\n",
    "ignore_cols = [c for c in ['patient_id','study_number','timehash','filepath'] if c in df.columns]\n",
    "sc.check_exact_row_duplicates(train_df, val_df, test_df, ignore_cols=ignore_cols)\n",
    "\n",
    "# Verificação temporal para até 3 colunas candidatas\n",
    "candidate_dates = [c for c in df.columns if any(k in c.lower() for k in ['date','time','timestamp','timehash'])]\n",
    "if candidate_dates:\n",
    "    for c in candidate_dates[:3]:\n",
    "        sc.check_temporal_leakage(train_df, val_df, test_df, datetime_col=c)\n",
    "else:\n",
    "    print('Nenhuma coluna temporal detectada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d3848",
   "metadata": {},
   "source": [
    "## 6) Organização YOLO (copiar imagens/labels) — opcional\n",
    "Mude `DO_ORGANIZE = True` acima para realmente copiar os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b10700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 📂 Movendo arquivos do split train (14170 amostras)\n",
      "INFO: 📂 Movendo arquivos do split val (4118 amostras)\n",
      "INFO: 📂 Movendo arquivos do split test (2039 amostras)\n",
      "INFO: ✅ Organização YOLO concluída em dataset_yolo\n",
      "INFO: Copied original meta.yaml from meta.yaml to dataset_yolo\\original_meta.yaml\n",
      "INFO: Updated data.yaml written to dataset_yolo\\data.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Organização YOLO concluída em dataset_yolo\n"
     ]
    }
   ],
   "source": [
    "if DO_ORGANIZE:\n",
    "    try:\n",
    "        sc.organize_yolo(splits_dir=OUTPUT_DIR, src_images=IMG_DIR, src_labels=LBL_DIR, dst_root=DST_ROOT)\n",
    "        print('✅ Organização YOLO concluída em', DST_ROOT)\n",
    "    except Exception as e:\n",
    "        print('Erro ao organizar YOLO:', e)\n",
    "else:\n",
    "    print('Organização YOLO desabilitada (DO_ORGANIZE=False)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
